{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6431b3-8f3d-424a-b464-ba5d65570783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (2.19.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b42f50-38c0-47be-86a9-54b16169588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ac7830-6c27-4d7a-a289-9fdde920b669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 564 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'C:/Users/tebrick_KING/FlavorSnap/train',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28573456-132c-469b-b3be-dae8832aca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 564 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'C:/Users/tebrick_KING/FlavorSnap/validation',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43412707-df54-4498-ae1d-3ceb4128f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 564 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'C:/Users/tebrick_KING/FlavorSnap/test',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26682015-38da-4be6-8989-6bb4bce34043",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# creating cache to make it easier to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a39813b-5046-489d-99ba-1b368f8b1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using convolution \n",
    "from tensorflow.keras import layers, models\n",
    "num_classes = 6\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(img_height, img_width, 3)),  # Explicit input layer\n",
    "    tf.keras.layers.Rescaling(1./255),  # No input_shape argument here\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')  # Add softmax activation\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7007c6cb-b5eb-4558-81d2-d62ade5e7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3d42b5-75d6-434e-89de-9ad8d848f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.8405 - loss: 0.4563 - val_accuracy: 0.8369 - val_loss: 0.4153\n",
      "Epoch 2/6\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.8496 - loss: 0.4326 - val_accuracy: 0.9379 - val_loss: 0.3062\n",
      "Epoch 3/6\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9559 - loss: 0.2243 - val_accuracy: 0.9699 - val_loss: 0.1306\n",
      "Epoch 4/6\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.9920 - loss: 0.0726 - val_accuracy: 0.9894 - val_loss: 0.0441\n",
      "Epoch 5/6\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.9919 - loss: 0.0446 - val_accuracy: 0.9858 - val_loss: 0.0507\n",
      "Epoch 6/6\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.9922 - loss: 0.0374 - val_accuracy: 0.9840 - val_loss: 0.0588\n"
     ]
    }
   ],
   "source": [
    "epochs = 6 \n",
    "\n",
    "history = model.fit(\n",
    "  train_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92ad189f-9303-4fd8-bc89-f95d4cdee4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 957ms/step - accuracy: 0.9836 - loss: 0.0503\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'Test Accuracy: {test_acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1a128-8121-4de6-9eb1-827ed55eeb4a",
   "metadata": {},
   "source": [
    "98% test accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4acdd80a-1456-404e-a707-2423d547fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# augument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d600fdd6-57d7-4328-bb39-70d7bc3f8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')  # Softmax added\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ad113bf-0ed8-4f78-8dc0-8bd95729e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36221f9f-62d8-434c-82dd-4892bc40d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98296e39-8f45-4a9f-be9a-a0d62ff0198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/tebrick_KING/FlavorSnap/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e5e493-ba8c-41f4-9f53-f99520221361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 16:18:16.624 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\tebrick_KING\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"C:/Users/tebrick_KING/FlavorSnap/model.keras\")\n",
    "\n",
    "# Class labels (modify based on your dataset)\n",
    "class_names = [\"Akara\", \"Bread\", \"Egusi\", \"Moi Moi\", \"Rice and Stew\", \"Yam\"]\n",
    "\n",
    "st.title(\"ðŸ” FlavorSnap - Food Recognition\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    img = Image.open(uploaded_file).resize((224, 224))\n",
    "    st.image(img, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "    # Preprocess image\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "    st.write(f\"### ðŸ·ï¸ Identified as: **{predicted_class}**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d645c0f0-730d-440e-802c-1a502bf4138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tebrick_king\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b5ea35-158b-45bd-853d-1ea694ae7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)  \n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"dataset/train\", transform=transform)\n",
    "test_data = datasets.ImageFolder(\"dataset/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9961247f-2d70-474e-83af-cf6722e17436",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT \n",
    "model = resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f9a2ae-dadb-4f9e-adaa-484d235e5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 41.9629\n",
      "Epoch 2, Loss: 13.6263\n",
      "Epoch 3, Loss: 9.0370\n",
      "Epoch 4, Loss: 5.6596\n",
      "Epoch 5, Loss: 3.1386\n",
      "Epoch 6, Loss: 2.0858\n",
      "Epoch 7, Loss: 2.7447\n",
      "Epoch 8, Loss: 4.3620\n",
      "Epoch 9, Loss: 4.3361\n",
      "Epoch 10, Loss: 2.4585\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae9aaee-688f-4dfd-9ee1-52e327052522",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"food_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ac04c6-9f30-4f21-87ab-17e93812e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def predict_image(image_path, model, class_names):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        return class_names[predicted.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c3c0cb-1d5d-4b7a-b0a6-6e3e0be74827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3976, Val Loss: 1.1969\n",
      "Epoch 2, Train Loss: 1.1767, Val Loss: 1.1439\n",
      "Epoch 3, Train Loss: 1.1425, Val Loss: 1.1354\n",
      "Epoch 4, Train Loss: 1.1218, Val Loss: 1.1157\n",
      "Epoch 5, Train Loss: 1.1238, Val Loss: 1.1870\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "import copy\n",
    "\n",
    "# Config\n",
    "DATA_DIR = \"dataset\"\n",
    "MODEL_PATH = \"food_classifier.pth\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30\n",
    "PATIENCE = 3  \n",
    "NUM_CLASSES = 6\n",
    "\n",
    "# Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "full_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(weights='DEFAULT')\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == PATIENCE:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "torch.save(best_model, MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971621ae-8371-46d9-b3e5-69b46dfb19b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
